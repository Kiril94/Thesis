{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run slicer with jupyter notebook firt pip_install('pip==new_version')\n",
    "then pip_install('ipywidgets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import split, join\n",
    "base_dir = split(os.getcwd())[0]\n",
    "if base_dir not in sys.path:\n",
    "    sys.path.append(base_dir)\n",
    "import pickle\n",
    "import slicer\n",
    "import JupyterNotebooksLib as slicernb\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from slicer.ScriptedLoadableModule import *\n",
    "from DICOMLib import DICOMUtils\n",
    "\n",
    "slicernb.AppWindow.setWindowSize(scale=0.5)\n",
    "slicernb.showSliceViewAnnotations(False)\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.use('WXAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "FILEBROWSER_PATH = os.path.join(os.getenv('WINDIR'), 'explorer.exe')\n",
    "\n",
    "def explore(path):\n",
    "    # explorer would choke on forward slashes\n",
    "    path = os.path.normpath(path)\n",
    "\n",
    "    if os.path.isdir(path):\n",
    "        subprocess.run([FILEBROWSER_PATH, path])\n",
    "    elif os.path.isfile(path):\n",
    "        subprocess.run([FILEBROWSER_PATH, '/select,', os.path.normpath(path)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Appendtext(fname, text):\n",
    "    with open(fname,'a+') as f:\n",
    "        f.write(text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = join(base_dir, 'data')\n",
    "tables_dir = join(data_dir, 'tables')\n",
    "data_long_dir = join(data_dir, 't1_longitudinal')\n",
    "log_file = join(data_long_dir, 'results', 'failed_pred.txt')\n",
    "disk_dir = \"F:\\\\\"\n",
    "pred_dir = join(disk_dir, \"CoBra\\\\Data\\\\volume_longitudinal_nii\\\\prediction\")\n",
    "with open(join(tables_dir, 'newIDs_dic.pkl'), 'rb') as f:\n",
    "    id_dic = pickle.load(f)\n",
    "with open(join(tables_dir, \"disk_series_directories.json\"), 'rb') as f:\n",
    "    dir_dic = json.load(f)\n",
    "inv_id_map = {v: k for k, v in id_dic.items()}\n",
    "with open(join(data_long_dir, \"failed_seg.pkl\"), 'rb') as f:\n",
    "    failed_seg_files = pickle.load(f)\n",
    "with open(join(data_long_dir, \"outliers_affected_br.pkl\"), 'rb') as f:\n",
    "    sids_outliers = pickle.load(f)\n",
    "\n",
    "df_volume_dir = pd.read_csv(join(tables_dir, 'series_directories.csv'))\n",
    "sif_volume_dir_dic = pd.Series(\n",
    "    df_volume_dir.Directory.values, index=df_volume_dir.SeriesInstanceUID)\\\n",
    "        .to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get stroke files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ids = [id_dic[sid_stroke] for sid_stroke in sids_outliers]\n",
    "out_niis_pred = [(join(pred_dir, id+'_1mm.nii.gz'), join(pred_dir, id+'_1mm_seg.nii.gz')) for id in out_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = [split(vol_file)[1][:6] for vol_file, _ in out_niis_pred]\n",
    "dcm_dirs = [dir_dic[inv_id_map[file_id]] for file_id in file_ids] \n",
    "for dcm_dir in dcm_dirs[:5]:\n",
    "    DICOMUtils.importDicom(dcm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 126 files in the database\n"
     ]
    }
   ],
   "source": [
    "print(\"There are now\",len(DICOMUtils.allSeriesUIDsInDatabase()),'files in the database')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicer.mrmlScene.Clear(False)\n",
    "file_num =75\n",
    "\n",
    "examine_file_id = None#'008309'\n",
    "if not isinstance(examine_file_id, type(None)):\n",
    "    files_vol_seg = [f for f in out_niis_pred if examine_file_id in f[0]]\n",
    "    print(files_vol_seg)\n",
    "    vol_file, seg_file = files_vol_seg[0][0], files_vol_seg[0][1]\n",
    "    print(vol_file)\n",
    "    file_id = examine_file_id\n",
    "else:\n",
    "    vol_file, seg_file = out_niis_pred[file_num]\n",
    "    file_id = split(vol_file)[1][:6]\n",
    "\n",
    "volume = slicer.util.loadVolume(vol_file)\n",
    "seg = slicer.util.loadSegmentation(seg_file)\n",
    "print(vol_file)\n",
    "print('new_id =', file_id)\n",
    "slicernb.ViewDisplay(\"\")\n",
    "#fig.savefig(join(data_long_dir, 'results','strokes', 'example1.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude_stroke_ids = []\n",
    "#load exclude stroke ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001015', '003917', '015017', '019148', '019130', '024408', '025717', '026927', '027622', '032903', '032888', '033936', '035763']\n"
     ]
    }
   ],
   "source": [
    "exclude_stroke_ids.append(file_id)\n",
    "print(exclude_stroke_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(data_long_dir, 'results','strokes','exclude_patients_with_large_strokes_ids.pkl'),'wb') as f:\n",
    "    pickle.dump(exclude_strokes_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ok'\n",
    "text = '\\n'+str(file_id) + ' ' + text\n",
    "Appendtext(log_file, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_dir = dir_dic[inv_id_map[file_id]]\n",
    "#dcm_files = [join(dcm_dir, file) for file in os.listdir(dcm_dir)]\n",
    "dcm_uid = split(dcm_dir)[1]\n",
    "print(dcm_dir)\n",
    "print('dcm_uid:', dcm_uid)\n",
    "print('sif_dir:', sif_volume_dir_dic[dcm_uid])\n",
    "slicer.mrmlScene.Clear(False)\n",
    "volume = DICOMUtils.loadSeriesByUID([dcm_uid])\n",
    "slicernb.ViewDisplay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\CoBra\\Data\\volume_longitudinal_nii\n"
     ]
    }
   ],
   "source": [
    "print(split(split(vol_file)[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_niis_and_pred = True\n",
    "if remove_niis_and_pred:\n",
    "    os.remove(vol_file)\n",
    "    os.remove(seg_file)\n",
    "    os.remove(join(split(vol_file)[0], file_id+'_seg.nii.gz'))\n",
    "    os.remove(join(split(split(vol_file)[0])[0], 'input', 'nii_files', file_id+'.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic 3d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GetFirstVolumeRenderingDisplayNode argument 1: method requires a VTK object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "In  \u001b[0;34m[11]\u001b[0m:\nLine \u001b[0;34m1\u001b[0m:     \n",
      "File \u001b[0;34mC:\\Users\\kiril\\Programs\\slicer\\Slicer 4.11.20210226\\NA-MIC\\Extensions-29738\\SlicerJupyter\\lib\\Slicer-4.11\\qt-scripted-modules\\JupyterNotebooksLib\\display.py\u001b[0m, in \u001b[0;32mshowVolumeRendering\u001b[0m:\nLine \u001b[0;34m377\u001b[0m:   displayNode = volRenLogic.GetFirstVolumeRenderingDisplayNode(volumeNode)\n",
      "\u001b[0;31mTypeError\u001b[0m: GetFirstVolumeRenderingDisplayNode argument 1: method requires a VTK object\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "slicernb.showVolumeRendering(volume, show=True)\n",
    "app = slicernb.AppWindow()\n",
    "app"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0a4e7c53876702b4a89fa263be312625f90a32415c93db3923bd26fa82850c2"
  },
  "kernelspec": {
   "display_name": "Slicer 4.11",
   "language": "python",
   "name": "slicer-4.11"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
